\documentclass[sigconf]{acmart}

\input{format/final}
\graphicspath{ {./images/}}
\usepackage{subcaption}
% \usepackage[table]{xcolor}
\usepackage{url}

\begin{document}
\title{Analyzing everyday challenges of people with visual impairments}


\author{Tousif Ahmed}
\orcid{HID237}
\affiliation{%
\institution{Indiana University}
  \streetaddress{150 S Woodlawn Avenue}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47405}
}
\email{touahmed@indiana.edu}



\begin{abstract}
       People with visual impairments face varieties of problem in their daily lives. Nowadays, modern technology especially camera-based technologies are helping people with visual impairment in their everyday tasks ranging from daily household activity to navigation. Users are using camera based applications where they are sharing photos and asking questions. Based on the asked question and shared photo, automated tools or human crowd workers are helping the visually impaired people in their tasks. By exploring the questions, it is possible to understand the problems and challenges of people with visual impairments. However, the volume of such data makes it impossible to analyze the questions manually.  Big data analytics could help us to understand the challenges of people with visual impairments. To understand the challenges, we analyzed the VizWiz data set which contains more than 33,500 questions asked by people with visual impairments. In this paper, we report on the data and shed light on the challenges.  

\end{abstract}

\keywords{E534, HID 237,  Big Data, Accessibility Issues, People with Visual Impairments}


\maketitle


\section{Introduction}
People with visual impairments face a variety of problems in their daily lives and need assistance. They need assistance with detecting objects, identifying money, navigation, transportation, household activities, cooking, and various other activities. Sighted person on rely on vision on so many things that it is almost impossible to visualize and understand the problems of people with visual impairments. Although there are variety of tools available to simulate the challenges and experiences of people with visual impairments, the challenges of people with visual impairments is not well understood. To help visually impaired people with technologies, we need to understand their problem first.

One possible to understand the challenges of people with visual impairments is qualitative analysis or ethnographic studies with people with visual impairments. Simply, researchers can follow or conduct interviews with people with visual impairments. Although qualitative studies are widely accepted research methods, it has limitations. Specially to understand the problems of people with visual impairments, qualitative studies have severe limitations. As the challenges vary with the experiences of people with visual impairments, these studies can not capture or depict the whole picture. Besides, these studies are very expensive and need ample human effort. Therefore, we need a better way to understand the challenges of people with visual impairments.

Big data analytics could be a potential alternative. To understand how big data can help people with visual impairments, we need to understand the backgroungd first. Nowadays, people with visual impairments uses different technologies for their problems.A wide range of technologies such as talking watch\footnote{https://www.maxiaids.com/talking-watches}, braille reader\footnote{\url{http://www.afb.org/prodBrowseCatResults.aspx?CatID=43}}, navigation helper \footnote{\url{http://www.gdp-research.com.au/}} are available in the market to help the visually impaired in their daily tasks. Since the introduction of smartphone, smartphone based applications gained huge popularities among people with visual impairments. Now, mobile and smartphone applications like Seeing AI~\cite{seeingai}, AiPoly~\cite{aipoly},LookTel~\cite{looktel}, and other such camera based applications are helping people with visual impairmentsin object recognition, face recognition, color detection, human emotion detection, activity recognition, and other such tasks that was not possible before. Figure ~\ref{fig:seeingai} depicts an example from Seeing AI which shows that how camera based applications are helping people with visual impairments by describing nearby person's activitty (Figure ~\ref{fig:ios}) and their facial emotions (Figure ~\ref{fig:facial}) .
\begin{figure}[tbp]
        \centering
        \begin{subfigure}[b]{0.4\columnwidth}
                %\includegraphics[width=\textwidth]{figures/appPermissions.pdf}  
                \includegraphics[width=\textwidth]{images/facial.pdf}  
                \caption{Age, gender, appearance, and facial expression} 
                  \label{fig:facial}   
        \end{subfigure}%
        ~ 
        \begin{subfigure}[b]{0.4\columnwidth}
                \includegraphics[width=\textwidth]{images/activity2.pdf}  
                 \caption{Age, gender, and activity of a nearby person}
                  \label{fig:ios}      
        \end{subfigure}%
        \caption{Seeing AI providing various information about people nearby~\cite{seeingai}.} 
        %Android currently displays the requested permissions during the app installation process. iOS  allows selective disabling of permissions for installed apps.}
        \label{fig:seeingai}
\end{figure}

Most of the camera assisted assitive applications works in one simple way.The user uploads an intended photo and asks a question about that. Applications have it's simple iq engine which tries to answer the problem first. If it's not able to answer that question, it shares the questions and images with the user's friends and family. Sometimes, the image is shared with a web based human worker. This crowd wroker is essential for such system, because the iq engine is not sophisticated yet. We can not completely trust the automated approaches.  Besides, visually impaired user's can not efficiently take photos. Sometimes they point at totally wrong objetcts or items, sometimes they share blurry photos, and even sometimes the question does not match with the photos~\cite{Jayant:2011,Bigham:2010,Harada:2013}. Therefore, to give a correct answer of the questions, technologies require human intelligence. Questions and answer based applications like TapTapSee~\cite{taptapsee} and VizWiz~\cite{Bigham:2010} uses this approach. LookTell~\cite{looktel} and BeMyEyes does not have any automated approach, it directly broadcasts the video feed to the volunteers and volunteers answer their questions. Some applications are trying to move towards the fully automated approach, however, due to the limitations of automated approaches they did not gain much popularity yet. 

Human based systems have privacy issues, because these users are uploading their photos which may contain sensitive information. Often they ask about medical information, their address, and various other sensitive information which can be exploited by the malicious crowd workers. Even sometimes, the users shares their credit card image and asks the system to about their credit card information which have severe privacy and security implications. Moreover, cameras and images shared by them can be extremely risky for people with visual impairments, becuase often they do not know the contents of the photo. Photos can be uploaded in error, sensitive data can be shared unintentionally. Ahmed et al.~\cite{Ahmed:2016} reported a scary story of one of the VizWiz users, who accidentally shared her naked photo with a crowd worker. Such evidents suggestsb that such systems has severe privacy and security implications. However, visually impaired needs such tool in their daily lives. Therefore, the ideal solution would be an completely automated approach. However, to design a flawless system we need to improve the existing tools first and we need to understand the challenges first.

The challenges of people with visual impairments can be easily understood from the images uploaded and questions asked by the user. Although it is extremely difficult for people with visual impairments to take a good photo, still they are using these tools because of their challenges. Therefore, the data uploaded in these applications are probably a good way to understand the challenges. However, due to the volume of the data it is not possible to manually identify the problems. Therefore, big data analytics can be helpful in this context to understand the challenges of people with visual impairments. However, due to privacy issues all but one data sets are not publicly available. 

In this paper, we analyzed the VizWiz data set containing more than 35000 images and questions~\cite{Bigham:2010}. Based on the questions asked, we tried to categorize their problems which eventually help the researchers to design and develop a fully automated system.Previous researches~\cite{Brady:2013} explored the same problem with the same data set. However, they only explored 1000 images and performed a qualitative study and identified four categories of problem. Since manual analysis is not possible on 35000 data, we used big data tools to automatically analyze the questions and images. In this paper, we report on analysis performed and the visual challenges of people with visual impairments.

\section{Methodology}
In this section, we discuss the methodology for identifying the challenges of people with visual impairments. 

\subsection{Data Set}
We used VizWiz data set which is the only available data set in this category. VizWiz is an iPhone application that allows visually impaired users to get quick responses of their challenges. The app tries to find an answer by using automatic IQ engine and anonymous crowd workers~\cite{vizwiz}. VizWiz was released in May, 2011. 

VizWiz application helped more than ten thousand users by answering more than 100,000 questions. However, they only shared half of their data from those participants who gave consent. There 

\begin{acks}

The authors would like to thank Professor Gregor von Laszewski for helping us with the instruction and resources that were required to complete this paper. We would also to like to thank the associate instructors for being available on the course website all the time and helping us with their answers.

\end{acks}



\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 
\newpage
\appendix

%We include an appendix with common issues that we see when students submit papers. One particular important issue is not to use the underscore in bibtex labels. Sharelatex allows this, but the proceedings script we have does not allow this.

%When you submit the paper you need to address each of the items in the
%issues.tex file and verify that you have done them. Please do this
%only at the end once you have finished writing the paper. To d this
%cange TODO with DONE. However if you check something on with DONE, but
%we find you actually have not executed it correcty, you will receive
%point deductions. Thus it is important to do this correctly and not
%just 5 minutes before the deadline. It is better to do a late
%submission than doing the check in haste. 

\input{issues}

\end{document}
